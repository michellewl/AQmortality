{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3cc8dd-8a38-4479-b98d-3d0fe6fabafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/mwlw3/miniconda3/envs/AQmort/lib/python3.9/site-packages/pyproj/__init__.py:89: UserWarning: pyproj unable to set database path.\n",
      "  _pyproj_global_context_initialize()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from PyBNG import PyBNG\n",
    "import shapely\n",
    "from os import makedirs, path, listdir, remove\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import requests\n",
    "import zipfile as zpf\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from ADMS_functions import PG_index, PointXYZ_to_latlon, plot_on_map, plot_in_grid_box, process_PG_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f03ca66-c5bd-4e1f-b75d-f20032b4d468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RUN 011\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Processing from raw ADMS-Urban outputs to a netCDF file with useful attributes and latitude/longitude coordinates\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(processed_coordinates_filepath):\n\u001b[0;32m---> 15\u001b[0m     new_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mconcat([process_PG_dataset(xr\u001b[38;5;241m.\u001b[39mopen_dataset(file)) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     new_ds\u001b[38;5;241m.\u001b[39mto_netcdf(processed_coordinates_filepath)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(processed_coordinates_filepath):\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Processing from raw ADMS-Urban outputs to a netCDF file with useful attributes and latitude/longitude coordinates\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(processed_coordinates_filepath):\n\u001b[0;32m---> 15\u001b[0m     new_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mprocess_PG_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     new_ds\u001b[38;5;241m.\u001b[39mto_netcdf(processed_coordinates_filepath)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(processed_coordinates_filepath):\n",
      "File \u001b[0;32m~/AQmortality/ADMS_functions.py:108\u001b[0m, in \u001b[0;36mprocess_PG_dataset\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_PG_dataset\u001b[39m(ds):\n\u001b[1;32m     96\u001b[0m     data_variables \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     97\u001b[0m         ds\u001b[38;5;241m.\u001b[39mDataset1\u001b[38;5;241m.\u001b[39mPollutant_Name: ([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPG_class\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspace\u001b[39m\u001b[38;5;124m\"\u001b[39m], ds\u001b[38;5;241m.\u001b[39mDataset1\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape((ds\u001b[38;5;241m.\u001b[39mdims[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnMetLines\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), ds\u001b[38;5;241m.\u001b[39mDataset1\u001b[38;5;241m.\u001b[39mattrs),\n\u001b[1;32m     98\u001b[0m         ds\u001b[38;5;241m.\u001b[39mDataset2\u001b[38;5;241m.\u001b[39mPollutant_Name: ([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPG_class\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspace\u001b[39m\u001b[38;5;124m\"\u001b[39m], ds\u001b[38;5;241m.\u001b[39mDataset2\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape((ds\u001b[38;5;241m.\u001b[39mdims[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnMetLines\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), ds\u001b[38;5;241m.\u001b[39mDataset2\u001b[38;5;241m.\u001b[39mattrs),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwind_direction\u001b[39m\u001b[38;5;124m\"\u001b[39m: ([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPG_class\u001b[39m\u001b[38;5;124m\"\u001b[39m], ds\u001b[38;5;241m.\u001b[39mMet_PHI\u001b[38;5;241m.\u001b[39mvalues, ds\u001b[38;5;241m.\u001b[39mMet_PHI\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[1;32m    104\u001b[0m                      }\n\u001b[1;32m    106\u001b[0m     coords \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPasquill-Gifford\u001b[39m\u001b[38;5;124m\"\u001b[39m: ([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPG_class\u001b[39m\u001b[38;5;124m\"\u001b[39m], np\u001b[38;5;241m.\u001b[39marray(PG_index)),\n\u001b[1;32m    107\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: ([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspace\u001b[39m\u001b[38;5;124m\"\u001b[39m], PointXYZ_to_latlon(ds\u001b[38;5;241m.\u001b[39mPointX_XYZ\u001b[38;5;241m.\u001b[39mvalues, ds\u001b[38;5;241m.\u001b[39mPointY_XYZ\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mlatitude\u001b[38;5;241m.\u001b[39mvalues),\n\u001b[0;32m--> 108\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: ([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspace\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[43mPointXYZ_to_latlon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPointX_XYZ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPointY_XYZ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlongitude\u001b[38;5;241m.\u001b[39mvalues)}\n\u001b[1;32m    110\u001b[0m     attrs \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mattrs\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mDataset(data_vars\u001b[38;5;241m=\u001b[39mdata_variables, coords\u001b[38;5;241m=\u001b[39mcoords, attrs\u001b[38;5;241m=\u001b[39mattrs)\n",
      "File \u001b[0;32m~/AQmortality/ADMS_functions.py:40\u001b[0m, in \u001b[0;36mPointXYZ_to_latlon\u001b[0;34m(PointXs, PointYs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, Y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(PointXs\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), PointYs\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m     39\u001b[0m     latlon \u001b[38;5;241m=\u001b[39m PyBNG(easting\u001b[38;5;241m=\u001b[39mX, northing\u001b[38;5;241m=\u001b[39mY)\u001b[38;5;241m.\u001b[39mget_latlon()\n\u001b[0;32m---> 40\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlatlon\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     42\u001b[0m df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AQmort/lib/python3.9/site-packages/pandas/core/frame.py:7982\u001b[0m, in \u001b[0;36mDataFrame.append\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   7979\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   7980\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m, other]\n\u001b[1;32m   7981\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 7982\u001b[0m     \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7986\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7987\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7988\u001b[0m )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/AQmort/lib/python3.9/site-packages/pandas/core/reshape/concat.py:298\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03malong the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03mValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    285\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    286\u001b[0m     objs,\n\u001b[1;32m    287\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    296\u001b[0m )\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AQmort/lib/python3.9/site-packages/pandas/core/reshape/concat.py:520\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    518\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 520\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_block_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy:\n\u001b[1;32m    524\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/miniconda3/envs/AQmort/lib/python3.9/site-packages/pandas/core/internals/concat.py:68\u001b[0m, in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m     66\u001b[0m         values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mview()\n\u001b[1;32m     67\u001b[0m     b \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mmake_block_same_class(values, placement\u001b[38;5;241m=\u001b[39mplacement)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43m_is_uniform_join_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     69\u001b[0m     blk \u001b[38;5;241m=\u001b[39m join_units[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mblock\n\u001b[1;32m     70\u001b[0m     vals \u001b[38;5;241m=\u001b[39m [ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n",
      "File \u001b[0;32m~/miniconda3/envs/AQmort/lib/python3.9/site-packages/pandas/core/internals/concat.py:491\u001b[0m, in \u001b[0;36m_is_uniform_join_units\u001b[0;34m(join_units)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03mCheck if the join units consist of blocks of uniform type that can\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03mbe concatenated using Block.concat_same_type instead of the generic\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m_concatenate_join_units (which uses `concat_compat`).\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# TODO: require dtype match in addition to same type?  e.g. DatetimeTZBlock\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m#  cannot necessarily join\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;66;03m# all blocks need to have the same type\u001b[39;00m\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mtype\u001b[39m(ju\u001b[38;5;241m.\u001b[39mblock) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(join_units[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mblock) \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units)  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;66;03m# no blocks that would get missing values (can lead to type upcasts)\u001b[39;00m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;66;03m# unless we're an extension dtype.\u001b[39;00m\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mju\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_na\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mju\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_extension\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mju\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;66;03m# no blocks with indexers (as then the dimensions do not fit)\u001b[39;00m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m ju\u001b[38;5;241m.\u001b[39mindexers \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;66;03m# only use this path when there is something to concatenate\u001b[39;00m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28mlen\u001b[39m(join_units) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    498\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/AQmort/lib/python3.9/site-packages/pandas/core/internals/concat.py:491\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03mCheck if the join units consist of blocks of uniform type that can\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03mbe concatenated using Block.concat_same_type instead of the generic\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m_concatenate_join_units (which uses `concat_compat`).\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# TODO: require dtype match in addition to same type?  e.g. DatetimeTZBlock\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m#  cannot necessarily join\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;66;03m# all blocks need to have the same type\u001b[39;00m\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mtype\u001b[39m(ju\u001b[38;5;241m.\u001b[39mblock) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(join_units[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mblock) \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units)  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;66;03m# no blocks that would get missing values (can lead to type upcasts)\u001b[39;00m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;66;03m# unless we're an extension dtype.\u001b[39;00m\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mju\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_na\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mis_extension \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;66;03m# no blocks with indexers (as then the dimensions do not fit)\u001b[39;00m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m ju\u001b[38;5;241m.\u001b[39mindexers \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;66;03m# only use this path when there is something to concatenate\u001b[39;00m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28mlen\u001b[39m(join_units) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    498\u001b[0m )\n",
      "File \u001b[0;32mpandas/_libs/properties.pyx:33\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/AQmort/lib/python3.9/site-packages/pandas/core/internals/concat.py:229\u001b[0m, in \u001b[0;36mJoinUnit.is_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     values_flat \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43misna_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues_flat\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AQmort/lib/python3.9/site-packages/pandas/core/dtypes/missing.py:619\u001b[0m, in \u001b[0;36misna_all\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;66;03m# must be PeriodDType\u001b[39;00m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np\u001b[38;5;241m.\u001b[39mdatetime64, np\u001b[38;5;241m.\u001b[39mtimedelta64))\n\u001b[0;32m--> 619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna_all\u001b[39m(arr: ArrayLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m    Optimized equivalent to isna(arr).all()\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m     total_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(arr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Auto-run data processing steps for ADMS-Urban outputs which were generated under Pasquill-Gifford conditions, for all regions\n",
    "\n",
    "runs = [\"011\", \"012\", \"013\"]\n",
    "\n",
    "NaN_pcent_threshold = 9\n",
    "\n",
    "for run in runs:\n",
    "    print(f\"\\n\\nRUN {run}\")\n",
    "    folder = f\"/home/users/mwlw3/ADMS-Urban/2018_P-G_classes/all_regions/{run}/\"\n",
    "    files = [path.join(folder, file) for file in listdir(folder) if path.splitext(file)[-1]==\".nc\"]\n",
    "    processed_coordinates_filepath = path.join(folder, \"raw_processed_coordinates.nc\")\n",
    "\n",
    "    # Processing from raw ADMS-Urban outputs to a netCDF file with useful attributes and latitude/longitude coordinates\n",
    "    if not path.exists(processed_coordinates_filepath):\n",
    "        print(f\"Loading raw data for run {run} and processing the netCDF coordinates...\")\n",
    "        new_ds = xr.concat([process_PG_dataset(xr.open_dataset(file)) for file in files], \"space\")\n",
    "        new_ds.to_netcdf(processed_coordinates_filepath)\n",
    "    elif path.exists(processed_coordinates_filepath):\n",
    "        new_ds = xr.open_dataset(processed_coordinates_filepath)\n",
    "        print(f\"Loaded the processed coordinate data for run {run}.\")\n",
    "\n",
    "    # Re-gridding the data to a latitude/longitude grid of highest relevant resolution\n",
    "    print(f\"Re-gridding run {run}...\")\n",
    "    xmin, ymin, xmax, ymax = gpd.points_from_xy(new_ds.longitude.values, \n",
    "                                                new_ds.latitude.values).total_bounds\n",
    "    found_one = False\n",
    "    n_cells = None\n",
    "    ref_cell = None\n",
    "    x_coords = None\n",
    "    y_coords = None\n",
    "    NaN_pcent_min = 100\n",
    "    print(\"Searching for optimal re-gridding parameters...\")\n",
    "    for test_n_cells in tqdm(range(300, 1, -1)):\n",
    "        cell_size = (xmax-xmin)/test_n_cells\n",
    "        grid_cells = [shapely.geometry.box(x0, y0, x0 - cell_size, y0 + cell_size) \n",
    "                  for x0 in np.arange(xmin, xmax + cell_size, cell_size) \n",
    "                  for y0 in np.arange(ymin, ymax + cell_size, cell_size)]\n",
    "        test_ref_cell = gpd.GeoDataFrame(grid_cells, columns=[\"geometry\"])\n",
    "        test_x_coords = test_ref_cell.centroid.x.round(12).drop_duplicates()\n",
    "        test_y_coords = test_ref_cell.centroid.y.round(12).drop_duplicates()\n",
    "        if len(test_ref_cell) == len(test_x_coords)*len(test_y_coords):\n",
    "            variable = \"NO2\"\n",
    "            i = 0\n",
    "            # Grid the timeseries data\n",
    "            cell_list = []\n",
    "            cell = test_ref_cell.copy()\n",
    "            class_gdf = gpd.GeoDataFrame(new_ds[variable][i, :].values, \n",
    "                             columns=[f\"class_{variable}\"], \n",
    "                             geometry=gpd.points_from_xy(new_ds.longitude.values, new_ds.latitude.values))\n",
    "            merge = gpd.sjoin(class_gdf, test_ref_cell, how=\"left\", predicate=\"within\")\n",
    "            dissolve = merge.dissolve(by=\"index_right\", aggfunc=\"mean\")\n",
    "            cell.loc[dissolve.index, f\"class_{variable}\"] = dissolve[f\"class_{variable}\"].values\n",
    "            cell_list.append(cell[f\"class_{variable}\"].values.reshape(len(test_x_coords),len(test_y_coords)))\n",
    "            # Stack the grids into a numpy array\n",
    "            classes_gridded = np.stack(cell_list, axis=-1)\n",
    "            NaN_percentage = ((np.sum(np.isnan(classes_gridded)) / (classes_gridded.shape[0] * classes_gridded.shape[1] * classes_gridded.shape[2]))*100)\n",
    "            if NaN_percentage <= NaN_pcent_threshold:\n",
    "                found_one = True\n",
    "                n_cells = test_n_cells\n",
    "                ref_cell = test_ref_cell\n",
    "                x_coords = test_x_coords\n",
    "                y_coords = test_y_coords\n",
    "                break\n",
    "            elif NaN_percentage < NaN_pcent_min and not NaN_percentage <= NaN_pcent_threshold:\n",
    "                NaN_pcent_min = NaN_percentage\n",
    "                n_cells = test_n_cells\n",
    "                ref_cell = test_ref_cell\n",
    "                x_coords = test_x_coords\n",
    "                y_coords = test_y_coords\n",
    "    if not found_one:\n",
    "        print(f\"Couldn't get data gaps below {NaN_pcent_threshold}%. Minimum achieved was {NaN_pcent_min.round(1)}%.\")\n",
    "        NaN_percentage = NaN_pcent_min\n",
    "\n",
    "    print(f\"Selected to re-grid with {n_cells} cells in the x direction, resulting in {NaN_percentage.round(1)}% NaN gaps in the data.\")\n",
    "    grid_name = f\"gridded_{n_cells}\"\n",
    "    variables = [var for var in list(new_ds.data_vars) if \"wind\" not in var]\n",
    "\n",
    "    for variable in variables:\n",
    "        filepath = path.join(folder, grid_name, f\"{variable}_PG_classes_grid.nc\")\n",
    "        if path.exists(filepath):\n",
    "            print(f\"{grid_name}/{variable}_PG_classes_grid.nc already exists.\")\n",
    "            continue\n",
    "        print(f\"Re-gridding run {run}, pollutant {variable}...\")\n",
    "\n",
    "        # Grid the timeseries data\n",
    "        cell_list = []\n",
    "        for i in range(0, new_ds.PG_class.shape[0]):\n",
    "            cell = ref_cell.copy()\n",
    "            class_gdf = gpd.GeoDataFrame(new_ds[variable][i, :].values, \n",
    "                             columns=[f\"class_{variable}\"], \n",
    "                             geometry=gpd.points_from_xy(new_ds.longitude.values, new_ds.latitude.values))\n",
    "            merge = gpd.sjoin(class_gdf, ref_cell, how=\"left\", predicate=\"within\")\n",
    "            dissolve = merge.dissolve(by=\"index_right\", aggfunc=\"mean\")\n",
    "            cell.loc[dissolve.index, f\"class_{variable}\"] = dissolve[f\"class_{variable}\"].values\n",
    "            cell_list.append(cell[f\"class_{variable}\"].values.reshape(len(x_coords),len(y_coords)))\n",
    "\n",
    "        # Stack the grids into a numpy array\n",
    "        classes_gridded = np.stack(cell_list, axis=-1)\n",
    "\n",
    "        # Create the xarray dataset\n",
    "        data_variables = {f\"{variable}\": ([\"longitude\", \"latitude\", \"PG_class\"], classes_gridded, new_ds[variable].attrs)\n",
    "                            }\n",
    "\n",
    "        coords = {\"longitude\": ([\"longitude\"], x_coords),\n",
    "                    \"latitude\": ([\"latitude\"], y_coords),\n",
    "                 \"PG_class\": ([\"PG_class\"], new_ds.PG_class.data)}\n",
    "\n",
    "        attrs = new_ds.attrs\n",
    "\n",
    "        classes_ds = xr.Dataset(data_vars=data_variables, coords=coords, attrs=attrs)\n",
    "\n",
    "        # Save to a netCDF file\n",
    "        if not path.exists(path.join(folder, grid_name)):\n",
    "            makedirs(path.join(folder, grid_name))\n",
    "        classes_ds.to_netcdf(filepath)\n",
    "        print(f\"Saved to {filepath}.\")\n",
    "        \n",
    "print(f\"Finished processing runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951ddba-8144-440d-972c-d8f360913521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AQmort",
   "language": "python",
   "name": "aqmort"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
