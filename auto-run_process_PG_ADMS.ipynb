{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03ca66-c5bd-4e1f-b75d-f20032b4d468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RUN 003\n",
      "Loaded the processed coordinate data for run 003.\n",
      "Re-gridding run 003...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/299 [00:44<36:05,  7.39s/it]\n",
      "Gridding PG classes:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected to re-grid with 295 cells in the x direction.\n",
      "Re-gridding run 003, pollutant NOx...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gridding PG classes: 100%|██████████| 7/7 [02:00<00:00, 17.18s/it]\n",
      "Gridding PG classes:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /home/users/mwlw3/ADMS-Urban/2018_P-G_classes/all_regions/003/gridded_295/NOx_PG_classes_grid.nc.\n",
      "Re-gridding run 003, pollutant NO2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gridding PG classes:  29%|██▊       | 2/7 [00:35<01:29, 17.85s/it]"
     ]
    }
   ],
   "source": [
    "# Auto-run data processing steps for ADMS-Urban outputs which were generated under Pasquill-Gifford conditions, for all regions\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from PyBNG import PyBNG\n",
    "import shapely\n",
    "from os import makedirs, path, listdir, remove\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import requests\n",
    "import zipfile as zpf\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from ADMS_functions import PointXYZ_to_latlon, plot_on_map, plot_in_grid_box, process_PG_dataset\n",
    "\n",
    "PG_index = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "\n",
    "runs = [\"003\", \"004\", \"005\", \"006\", \"007\", \"008\", \"009\", \"010\"]\n",
    "\n",
    "for run in runs:\n",
    "    print(f\"\\n\\nRUN {run}\")\n",
    "    folder = f\"/home/users/mwlw3/ADMS-Urban/2018_P-G_classes/all_regions/{run}/\"\n",
    "    files = [path.join(folder, file) for file in listdir(folder) if path.splitext(file)[-1]==\".nc\"]\n",
    "    processed_coordinates_filepath = path.join(folder, \"raw_processed_coordinates.nc\")\n",
    "\n",
    "    # Processing from raw ADMS-Urban outputs to a netCDF file with useful attributes and latitude/longitude coordinates\n",
    "    if not path.exists(processed_coordinates_filepath):\n",
    "        print(f\"Processing the coordinates for run {run}...\")\n",
    "        progress_bar = tqdm(range(0, len(files)))\n",
    "        new_ds = xr.concat([process_PG_dataset(xr.open_dataset(files[i])) for i in progress_bar], \"space\")\n",
    "        new_ds.to_netcdf(processed_coordinates_filepath)\n",
    "    elif path.exists(processed_coordinates_filepath):\n",
    "        new_ds = xr.open_dataset(processed_coordinates_filepath)\n",
    "        print(f\"Loaded the processed coordinate data for run {run}.\")\n",
    "\n",
    "    # Re-gridding the data to a latitude/longitude grid of highest relevant resolution\n",
    "    print(f\"Re-gridding run {run}...\")\n",
    "    xmin, ymin, xmax, ymax = gpd.points_from_xy(new_ds.longitude.values, \n",
    "                                                new_ds.latitude.values).total_bounds\n",
    "    found_one = False\n",
    "    n_cells = None\n",
    "    ref_cell = None\n",
    "    x_coords = None\n",
    "    y_coords = None\n",
    "\n",
    "    for test_n_cells in tqdm(range(300, 1, -1)):\n",
    "        cell_size = (xmax-xmin)/test_n_cells\n",
    "        grid_cells = [shapely.geometry.box(x0, y0, x0 - cell_size, y0 + cell_size) \n",
    "                  for x0 in np.arange(xmin, xmax + cell_size, cell_size) \n",
    "                  for y0 in np.arange(ymin, ymax + cell_size, cell_size)]\n",
    "        test_ref_cell = gpd.GeoDataFrame(grid_cells, columns=[\"geometry\"])\n",
    "        test_x_coords = test_ref_cell.centroid.x.round(12).drop_duplicates()\n",
    "        test_y_coords = test_ref_cell.centroid.y.round(12).drop_duplicates()\n",
    "        if len(test_ref_cell) == len(test_x_coords)*len(test_y_coords):\n",
    "            found_one = True\n",
    "            n_cells = test_n_cells\n",
    "            ref_cell = test_ref_cell\n",
    "            x_coords = test_x_coords\n",
    "            y_coords = test_y_coords\n",
    "        elif found_one and not len(test_ref_cell) == len(test_x_coords)*len(test_y_coords):\n",
    "            break\n",
    "    print(f\"Selected to re-grid with {n_cells} cells in the x direction.\")\n",
    "    grid_name = f\"gridded_{n_cells}\"\n",
    "    variables = [var for var in list(new_ds.data_vars) if \"wind\" not in var]\n",
    "\n",
    "    for variable in variables:\n",
    "        print(f\"Re-gridding run {run}, pollutant {variable}...\")\n",
    "\n",
    "        # Grid the timeseries data\n",
    "        cell_list = []\n",
    "        progress_bar = tqdm(range(0, new_ds.PG_class.shape[0]))\n",
    "\n",
    "        for i in progress_bar:\n",
    "            progress_bar.set_description(f\"Gridding PG classes\")\n",
    "            cell = ref_cell.copy()\n",
    "            class_gdf = gpd.GeoDataFrame(new_ds[variable][i, :].values, \n",
    "                             columns=[f\"class_{variable}\"], \n",
    "                             geometry=gpd.points_from_xy(new_ds.longitude.values, new_ds.latitude.values))\n",
    "            merge = gpd.sjoin(class_gdf, ref_cell, how=\"left\", predicate=\"within\")\n",
    "            dissolve = merge.dissolve(by=\"index_right\", aggfunc=\"mean\")\n",
    "            cell.loc[dissolve.index, f\"class_{variable}\"] = dissolve[f\"class_{variable}\"].values\n",
    "            cell_list.append(cell[f\"class_{variable}\"].values.reshape(len(x_coords),len(y_coords)))\n",
    "\n",
    "        # Stack the grids into a numpy array\n",
    "        classes_gridded = np.stack(cell_list, axis=-1)\n",
    "\n",
    "        # Create the xarray dataset\n",
    "        data_variables = {f\"{variable}\": ([\"longitude\", \"latitude\", \"PG_class\"], classes_gridded, new_ds[variable].attrs)\n",
    "                            }\n",
    "\n",
    "        coords = {\"longitude\": ([\"longitude\"], x_coords),\n",
    "                    \"latitude\": ([\"latitude\"], y_coords),\n",
    "                 \"PG_class\": ([\"PG_class\"], new_ds.PG_class.data)}\n",
    "\n",
    "        attrs = new_ds.attrs\n",
    "\n",
    "        classes_ds = xr.Dataset(data_vars=data_variables, coords=coords, attrs=attrs)\n",
    "\n",
    "        # Save to a netCDF file\n",
    "        if not path.exists(path.join(folder, grid_name)):\n",
    "            makedirs(path.join(folder, grid_name))\n",
    "        filepath = path.join(folder, grid_name, f\"{variable}_PG_classes_grid.nc\")\n",
    "        classes_ds.to_netcdf(filepath)\n",
    "        print(f\"Saved to {filepath}.\")\n",
    "        \n",
    "print(f\"Finished processing runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee959f4d-27e7-4246-9192-bc59b7fa428d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AQmort",
   "language": "python",
   "name": "aqmort"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
