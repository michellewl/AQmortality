{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_classes import LAQNData, HealthData, MetData, IncomeData\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path, listdir\n",
    "import wandb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"architecture\": \"linear_regressor\",\n",
    "    \"train_size\": 0.8,\n",
    "    \"species\": \"NO2\",\n",
    "    \"spatial_resolution\": \"regional\",\n",
    "    \"temporal_resolution\": \"daily\",\n",
    "    \"input_artifacts\": [\"laqn-regional\", \"met-resample\", \"income-regional\"],\n",
    "    \"met_variables\": [\"temperature\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be moved to model_classes script when finished developing.\n",
    "\n",
    "class HealthModel():\n",
    "    def __init__(self, species, spatial_resolution, temporal_resolution, input_artifacts, met_variables):\n",
    "        self.species = species\n",
    "        self.spatial_resolution = spatial_resolution\n",
    "        self.temporal_resolution = temporal_resolution\n",
    "        self.input_artifacts = input_artifacts\n",
    "        self.met_variables = met_variables\n",
    "\n",
    "    def preprocess_and_log(self, train_size):\n",
    "        with wandb.init(project=\"AQmortality\", job_type=\"split-normalise-data\") as run:\n",
    "            df = pd.DataFrame()\n",
    "            # use dataset artifacts\n",
    "            for artifact in self.input_artifacts:\n",
    "                data_artifact = run.use_artifact(f\"{artifact}:latest\")\n",
    "                data_folder = data_artifact.download()\n",
    "                if artifact == \"met-resample\":\n",
    "                    for variable in self.met_variables:\n",
    "                        file = f\"{variable}.npz\"\n",
    "                        data = np.load(path.join(data_folder, file), allow_pickle=True)\n",
    "                        if df.empty:\n",
    "                            df = pd.DataFrame(index=pd.DatetimeIndex(data[\"x\"]), data=data[\"y\"], columns=[variable])\n",
    "                        else:\n",
    "                            df = df.join(pd.DataFrame(index=pd.DatetimeIndex(data[\"x\"]), data=data[\"y\"], columns=[variable]))\n",
    "                else:\n",
    "                    file = listdir(data_folder)[0]\n",
    "                    data = np.load(path.join(data_folder, file), allow_pickle=True)\n",
    "                    if df.empty:\n",
    "                        df = pd.DataFrame(index=pd.DatetimeIndex(data[\"x\"]), data=data[\"y\"], columns=[file.replace(\".npz\", \"\")])\n",
    "                    else:\n",
    "                        df = df.join(pd.DataFrame(index=pd.DatetimeIndex(data[\"x\"]), data=data[\"y\"], columns=[file.replace(\".npz\", \"\")]))\n",
    "\n",
    "            target_artifact = run.use_artifact(\"mortality-scaled:latest\")\n",
    "            target_folder = target_artifact.download()\n",
    "            data = np.load(path.join(target_folder, \"deaths.npz\"), allow_pickle=True)\n",
    "            df = df.join(pd.DataFrame(index=pd.DatetimeIndex(data[\"x\"]), data=data[\"y\"]*100000, columns=[\"deaths\"]))\n",
    "            df = df.dropna(axis=0)\n",
    "\n",
    "            # make new train and test artifacts for regional scale data\n",
    "            index = {\"train\": df.index[:int(len(df.index)*train_size)],\n",
    "                    \"test\": df.index[int(len(df.index)*train_size):]}\n",
    "            scaler = MinMaxScaler()\n",
    "            x_scaler = scaler.fit(df.loc[train_index].drop(\"deaths\", axis=1))\n",
    "            for subset in [\"train\", \"test\"]:\n",
    "                x = x_scaler.transform(df.loc[index[subset]].drop(\"deaths\", axis=1))\n",
    "                y = df.loc[index[subset]][\"deaths\"].values\n",
    "                subset_data = wandb.Artifact(\n",
    "                            f\"xy_{subset}\", type=\"dataset\",\n",
    "                            description=f\"Input features (normalised) and targets for {subset}ing set.\",\n",
    "                            metadata={\"input_shape\":x.shape,\n",
    "                                     \"target_shape\":y.shape,\n",
    "                                     \"species\": self.species,\n",
    "                                      \"spatial_resolution\": self.spatial_resolution,\n",
    "                                      \"temporal_resolution\": self.temporal_resolution,\n",
    "                                      \"input_artifacts\": self.input_artifacts,\n",
    "                                      \"met_variables\": self.met_variables})\n",
    "                with subset_data.new_file(subset + \".npz\", mode=\"wb\") as file:\n",
    "                    np.savez(file, x=x, y=y)\n",
    "                run.log_artifact(subset_data)\n",
    "    \n",
    "#     def train_and_log():\n",
    "#         with wandb.init(project=\"AQmortality\", job_type=\"train-regional-model\") as run:\n",
    "    # train linear regression model\n",
    "    # log model training metrics\n",
    "    # log trained model artifact – include input features description\n",
    "    \n",
    "    \n",
    "#     def test_and_log():\n",
    "#         with wandb.init(project=\"AQmortality\", job_type=\"test-regional-model\") as run:\n",
    "    # use regional test data artifacts\n",
    "    # normalise the inputs using the scaler fitted to the train set\n",
    "    # use trained model artifact\n",
    "    # test linear regression model\n",
    "    # log model test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HealthModel(\n",
    "    species=config[\"species\"], \n",
    "    spatial_resolution=config[\"spatial_resolution\"], \n",
    "    temporal_resolution=config[\"temporal_resolution\"], \n",
    "    input_artifacts=config[\"input_artifacts\"], \n",
    "    met_variables=config[\"met_variables\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sweet-forest-137</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/michellewl/AQmortality\" target=\"_blank\">https://wandb.ai/michellewl/AQmortality</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/michellewl/AQmortality/runs/3cwoauos\" target=\"_blank\">https://wandb.ai/michellewl/AQmortality/runs/3cwoauos</a><br/>\n",
       "                Run data is saved locally in <code>/home/users/mwlw3/AQmortality/wandb/run-20210519_174036-3cwoauos</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2181<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7478419d08f4a12a802f0a979571263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/users/mwlw3/AQmortality/wandb/run-20210519_174036-3cwoauos/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/users/mwlw3/AQmortality/wandb/run-20210519_174036-3cwoauos/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">sweet-forest-137</strong>: <a href=\"https://wandb.ai/michellewl/AQmortality/runs/3cwoauos\" target=\"_blank\">https://wandb.ai/michellewl/AQmortality/runs/3cwoauos</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.preprocess_and_log(train_size=config[\"train_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AQmort",
   "language": "python",
   "name": "aqmort"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
